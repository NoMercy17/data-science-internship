import os
import pandas as pd
import numpy as np
from scripts.feature_engineering import HotelFeatureExtractor
import warnings
warnings.filterwarnings('ignore')

def test_feature_engineering_pipeline():
    """
    Simple test to show before/after feature engineering transformations
    """
    
    # Configuration
    input_path = '/home/antonios/Desktop/Practica_de_vara/data-science-internship/data/cleaned/final_cleaned_data.pkl'
    output_dir = '/home/antonios/Desktop/Practica_de_vara/data-science-internship/data/results'
    
    print("="*80)
    print("FEATURE ENGINEERING PIPELINE TEST")
    print("="*80)
    
    # Load original data
    print("\nðŸ“ Loading original data...")
    if input_path.endswith('.pkl'):
        original_data = pd.read_pickle(input_path)
    else:
        original_data = pd.read_csv(input_path)
    
    print(f"âœ… Data loaded successfully!")
    
    # ============================================================================
    # BEFORE FEATURE ENGINEERING
    # ============================================================================
    print("\n" + "="*60)
    print("ðŸ” BEFORE FEATURE ENGINEERING")
    print("="*60)
    
    print(f"ðŸ“Š Original Data Shape: {original_data.shape}")
    print(f"ðŸ“ Total Original Columns: {len(original_data.columns)}")
    
    print(f"\nðŸ“‹ Original Column Names:")
    for i, col in enumerate(original_data.columns, 1):
        print(f"  {i:2d}. {col}")
    
    print(f"\nðŸ“ Categorical Columns:")
    categorical_cols = original_data.select_dtypes(include=['object', 'category']).columns.tolist()
    for col in categorical_cols:
        unique_count = original_data[col].nunique()
        print(f"  â€¢ {col} ({unique_count} unique values)")
    
    # ============================================================================
    # RUN FEATURE ENGINEERING
    # ============================================================================
    print("\n" + "="*60)
    print("âš™ï¸  RUNNING FEATURE ENGINEERING PIPELINE")
    print("="*60)
    
    # Initialize feature extractor
    extractor = HotelFeatureExtractor(output_dir=output_dir)
    
    # Create a copy to avoid modifying original
    data_copy = original_data.copy()
    
    # Step-by-step feature engineering
    print("\nðŸ”„ Step 1: Handling high cardinality features...")
    data_copy = extractor.handle_high_cardinality_features(data_copy)
    
    print("ðŸ”„ Step 2: Extracting temporal features...")
    data_copy = extractor.extract_temporal_features(data_copy)
    
    print("ðŸ”„ Step 3: Extracting customer behavior features...")
    data_copy = extractor.extract_customer_behavior_features(data_copy)
    
    print("ðŸ”„ Step 4: Extracting booking risk features...")
    data_copy = extractor.extract_booking_risk_features(data_copy)
    
    print("ðŸ”„ Step 5: Extracting market features...")
    data_copy = extractor.extract_market_features(data_copy)
    
    print("ðŸ”„ Step 6: Encoding categorical variables...")
    engineered_data = extractor.encode_categorical_variables(data_copy)
    
    # ============================================================================
    # AFTER FEATURE ENGINEERING
    # ============================================================================
    print("\n" + "="*60)
    print("âœ¨ AFTER FEATURE ENGINEERING")
    print("="*60)
    
    print(f"ðŸ“Š Engineered Data Shape: {engineered_data.shape}")
    print(f"ðŸ“ Total Engineered Columns: {len(engineered_data.columns)}")
    print(f"ðŸ“ˆ New Features Created: {len(engineered_data.columns) - len(original_data.columns)}")
    
    # ============================================================================
    # FEATURE ANALYSIS
    # ============================================================================
    print("\n" + "="*60)
    print("ðŸ” FEATURE TRANSFORMATION ANALYSIS")
    print("="*60)
    
    # Original features that remain
    original_features_kept = [col for col in original_data.columns if col in engineered_data.columns]
    print(f"\nâœ… Original Features Kept ({len(original_features_kept)}):")
    for col in original_features_kept:
        print(f"  â€¢ {col}")
    
    # Features that were removed/transformed
    removed_features = [col for col in original_data.columns if col not in engineered_data.columns]
    print(f"\nâŒ Original Features Removed/Transformed ({len(removed_features)}):")
    for col in removed_features:
        print(f"  â€¢ {col}")
    
    # New engineered features
    new_features = [col for col in engineered_data.columns if col not in original_data.columns]
    print(f"\nðŸ†• New Engineered Features ({len(new_features)}):")
    
    # Categorize new features
    temporal_features = [col for col in new_features if any(keyword in col.lower() for keyword in 
                        ['season', 'quarter', 'weekend', 'holiday', 'lead_time', 'advance', 'last_minute'])]
    
    customer_features = [col for col in new_features if any(keyword in col.lower() for keyword in 
                        ['loyalty', 'party', 'family', 'group', 'children', 'babies', 'business', 'experience', 'stay'])]
    
    risk_features = [col for col in new_features if any(keyword in col.lower() for keyword in 
                    ['risk', 'mismatch', 'changes', 'complexity', 'price', 'adr', 'revenue', 'booking_value'])]
    
    market_features = [col for col in new_features if any(keyword in col.lower() for keyword in 
                      ['online', 'agent', 'company', 'channel', 'segment', 'corporate', 'direct', 'travel'])]
    
    dummy_features = [col for col in new_features if '_' in col and any(col.startswith(prefix + '_') for prefix in 
                     ['meal', 'market_segment', 'distribution_channel', 'deposit_type', 'reserved_room_type', 
                      'assigned_room_type', 'booking_season', 'lead_time_category', 'customer_experience_level', 
                      'cancellation_tendency', 'avg_stay_preference', 'price_category', 'deposit_risk'])]
    
    grouping_features = [col for col in new_features if 'grouped' in col.lower()]
    
    print(f"\nðŸ•’ Temporal Features ({len(temporal_features)}):")
    for col in temporal_features:
        print(f"  â€¢ {col}")
    
    print(f"\nðŸ‘¥ Customer Behavior Features ({len(customer_features)}):")
    for col in customer_features:
        print(f"  â€¢ {col}")
    
    print(f"\nâš ï¸  Risk Assessment Features ({len(risk_features)}):")
    for col in risk_features:
        print(f"  â€¢ {col}")
    
    print(f"\nðŸ¢ Market Features ({len(market_features)}):")
    for col in market_features:
        print(f"  â€¢ {col}")
    
    if grouping_features:
        print(f"\nðŸ”— Grouped Features (High Cardinality Handling) ({len(grouping_features)}):")
        for col in grouping_features:
            print(f"  â€¢ {col}")
    
    print(f"\nðŸ·ï¸  Dummy Variables (One-Hot Encoded) ({len(dummy_features)}):")
    # Group dummy variables by their prefix
    dummy_groups = {}
    for col in dummy_features:
        prefix = col.split('_')[0] + '_' + col.split('_')[1] if len(col.split('_')) > 1 else col
        if prefix not in dummy_groups:
            dummy_groups[prefix] = []
        dummy_groups[prefix].append(col)
    
    for prefix, cols in dummy_groups.items():
        print(f"  ðŸ“‹ {prefix} ({len(cols)} categories):")
        for col in cols[:3]:  # Show first 3 categories
            print(f"    â€¢ {col}")
        if len(cols) > 3:
            print(f"    ... and {len(cols) - 3} more")
    
    # ============================================================================
    # ENCODING INFORMATION
    # ============================================================================
    print("\n" + "="*60)
    print("ðŸ”§ ENCODING TRANSFORMATIONS")
    print("="*60)
    
    if hasattr(extractor, 'label_encoders') and extractor.label_encoders:
        print(f"\nðŸ“Š Label Encoding Applied to ({len(extractor.label_encoders)}) columns:")
        for col, encoder in extractor.label_encoders.items():
            classes = encoder.classes_
            print(f"  â€¢ {col}: {len(classes)} categories")
            if len(classes) <= 8:
                mapping = dict(zip(classes, encoder.transform(classes)))
                print(f"    Mapping: {mapping}")
            else:
                print(f"    Categories: {classes[:3]}... (showing first 3)")
    
    # ============================================================================
    # TRANSFORMATION SUMMARY
    # ============================================================================
    print("\n" + "="*60)
    print("ðŸ“ˆ TRANSFORMATION SUMMARY")
    print("="*60)
    
    print(f"\nðŸ“‹ Feature Engineering Results:")
    print(f"  â€¢ Original Features: {len(original_data.columns)}")
    print(f"  â€¢ Features After Engineering: {len(engineered_data.columns)}")
    print(f"  â€¢ New Features Created: {len(new_features)}")
    print(f"  â€¢ Features Removed/Transformed: {len(removed_features)}")
    print(f"  â€¢ Growth Factor: {len(engineered_data.columns) / len(original_data.columns):.2f}x")
    
    print(f"\nðŸ’¾ Data Types After Engineering:")
    dtype_counts_after = engineered_data.dtypes.value_counts()
    for dtype, count in dtype_counts_after.items():
        print(f"  â€¢ {dtype}: {count} columns")
    
    # ============================================================================
    # SAVE RESULTS (ONLY 2 FILES)
    # ============================================================================
    print("\n" + "="*60)
    print("ðŸ’¾ SAVING RESULTS")
    print("="*60)
    
    # 1. Save engineered data as pickle (preserves data types)
    pickle_output_path = os.path.join(output_dir, 'feature_engineered_data.pkl')
    engineered_data.to_pickle(pickle_output_path)
    print(f"âœ… Engineered data saved to: {pickle_output_path}")
    
    # 2. Save CSV for quick inspection
    csv_output_path = os.path.join(output_dir, 'feature_engineered_data.csv')
    engineered_data.to_csv(csv_output_path, index=False)
    print(f"âœ… CSV version saved to: {csv_output_path}")
    
    print("\n" + "="*80)
    print("âœ¨ FEATURE ENGINEERING PIPELINE TEST COMPLETED SUCCESSFULLY!")
    print(f"ðŸ“ Files saved: {pickle_output_path}, {csv_output_path}")
    print("="*80)
    
    return engineered_data

if __name__ == "__main__":
    try:
        engineered_data = test_feature_engineering_pipeline()
        print(f"\nðŸŽ‰ Success! Final engineered dataset shape: {engineered_data.shape}")
    except Exception as e:
        print(f"\nâŒ Error occurred: {str(e)}")
        import traceback
        traceback.print_exc()